import PySimpleGUI as sg
import cv2 as cv
from PIL import Image
import io
import face_recognition
import os
import re

layout = [[sg.Text('Smart CCTV Surveillance Application'),],
          [sg.ReadButton('Monitor', size=(10, 1), pad=((200, 0), 3), font='Helvetica 14'),
           sg.RButton('DataSet', size=(10,1), font='Helvetica 14'),
           sg.RButton('Exit', size=(10,1), font='Helvetica 14')]]

win1 = sg.Window('Smart CCTV Surveillance Application-Home').Layout(layout)
win2_active=False
win3_active=False
while True:
    ev1, vals1 = win1.Read(timeout=100)
    if ev1 == 'Exit' or ev1 is None:
        break
    if ev1 == 'Monitor'  and not win2_active:
        win2_active = True
        win1.Hide()
        # define the window layout
        sg.ChangeLookAndFeel('LightGreen')
        layout2 = [
            [sg.Text('Smart CCTV Surveillance Application', size=(40, 1), justification='center', font='Helvetica 14')],
            [sg.Image(filename='', key='image1')],
            [sg.ReadButton('Exit', size=(10, 1), pad=((200, 0), 3), font='Helvetica 14')]]

        win2 = sg.Window('Smart CCTV Surveillance Application - Monitor')
        win2.Layout(layout2).Finalize()
        video_capture = cv.VideoCapture(0)

        # Create arrays of known face encodings and their names
        known_face_encodings = []
        known_face_names = []
        image_files_in_folder = [os.path.join('dataset/', f) for f in os.listdir('dataset/') if re.match(r'.*\.(jpg|jpeg|png)', f, flags=re.I)]
        for file in image_files_in_folder:
            basename = os.path.splitext(os.path.basename(file))[0]
            img = face_recognition.load_image_file(file)
            encodings = face_recognition.face_encodings(img)

            if len(encodings) > 1:
                print("WARNING: More than one face found in {}. Only considering the first face.".format(file))

            if len(encodings) == 0:
                print("WARNING: No faces found in {}. Ignoring file.".format(file))
            else:
                known_face_names.append(basename)
                known_face_encodings.append(encodings[0])


        # Initialize some variables
        face_locations = []
        face_encodings = []
        face_names = []
        process_this_frame = True

        while True:
            # Grab a single frame of video
            ret, frame = video_capture.read()

            # Resize frame of video to 1/4 size for faster face recognition processing
            small_frame = cv.resize(frame, (0, 0), fx=0.25, fy=0.25)

            # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)
            rgb_small_frame = small_frame[:, :, ::-1]

            # Only process every other frame of video to save time
            if process_this_frame:
                # Find all the faces and face encodings in the current frame of video
                face_locations = face_recognition.face_locations(rgb_small_frame)
                face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)

                face_names = []
                for face_encoding in face_encodings:
                    # See if the face is a match for the known face(s)
                    matches = face_recognition.compare_faces(known_face_encodings, face_encoding)
                    name = "Unknown"

                    # If a match was found in known_face_encodings, just use the first one.
                    if True in matches:
                        first_match_index = matches.index(True)
                        name = known_face_names[first_match_index]

                    face_names.append(name)

            process_this_frame = not process_this_frame

            # Display the results
            for (top, right, bottom, left), name in zip(face_locations, face_names):
                # Scale back up face locations since the frame we detected in was scaled to 1/4 size
                top *= 4
                right *= 4
                bottom *= 4
                left *= 4

                # Draw a box around the face
                cv.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)

                # Draw a label with a name below the face
                cv.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv.FILLED)
                font = cv.FONT_HERSHEY_DUPLEX
                cv.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)

            # Display the resulting image

            # let img be the PIL image
            img = Image.fromarray(frame)  # create PIL image from frame
            bio = io.BytesIO()  # a binary memory resident stream
            img.save(bio, format='PNG')  # save image as png to it
            imgbytes = bio.getvalue()  # this can be used by OpenCV hopefully
            win2.FindElement('image1').Update(data=imgbytes)

            ev2, vals2 = win2.ReadNonBlocking()
            if ev2 == 'Exit':
                video_capture.release()
                cv.destroyAllWindows()
                win2.Close()
                win2_active = False
                win1.UnHide()
                break
    if ev1 == 'DataSet' and not win3_active:
        win3_active = True
        win1.Hide()
        # define the window layout
        sg.ChangeLookAndFeel('LightGreen')
        layout3 = [
            [sg.Text('Smart CCTV Surveillance Application', size=(40, 1), justification='center', font='Helvetica 14')],
            [sg.Image(filename='', key='image')],
            [sg.Text('Please enter Name')],
            [sg.Text('Name', size=(15, 1)), sg.InputText('name')],
            [sg.ReadButton('Snapshot', size=(10, 1), pad=((200, 0), 3), font='Helvetica 14'),
             sg.RButton('Exit', size=(10, 1), font='Any 14')]]

        win3 = sg.Window('Smart CCTV Surveillance Application - DataSet')
        win3.Layout(layout3).Finalize()
        cap = cv.VideoCapture(0)
        while True:
            ret, frame = cap.read()

            gray = cv.cvtColor(frame, cv.COLOR_BGR2RGBA)

            # let img be the PIL image
            img = Image.fromarray(gray)  # create PIL image from frame
            bio = io.BytesIO()  # a binary memory resident stream
            img.save(bio, format='PNG')  # save image as png to it
            imgbytes = bio.getvalue()  # this can be used by OpenCV hopefully
            win3.FindElement('image').Update(data=imgbytes)

            ev3, vals3 = win3.ReadNonBlocking()
            if ev3 == 'Exit':
                cap.release()
                cv.destroyAllWindows()
                win3.Close()
                win3_active = False
                win1.UnHide()
                break
            elif ev3 == 'Snapshot':
                img.save('dataset/' + vals3[0]+'.png', format='PNG')



#########################################################################################################################